name: Daily Ingredient Scraper

on:
  schedule:
    - cron: '0 12 * * *'
  workflow_dispatch:
    inputs:
      zip_code:
        description: 'Zip code for scraping'
        required: false
        default: '94704'

jobs:
  scrape-ingredients:
    name: Scrape and Maintain
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Database Maintenance (Pre-Scrape Reset)
        env:
          DB_URL: ${{ secrets.DATABASE_URL }}
        run: |
          echo "ðŸ§¹ Clearing ingredients_recent to prepare for new data..."
          # This ensures the 'Recent' table is empty before the new scrape starts
          psql "$DB_URL" -c "TRUNCATE TABLE public.ingredients_recent;"
          
          echo "ðŸ“Š Maintenance complete. Database is ready for new batch."

      - name: Run Daily Scraper
        env:
          VERCEL_URL: ${{ secrets.VERCEL_URL || 'https://the-secret-sauce.vercel.app' }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          ZIP_CODE: ${{ github.event.inputs.zip_code || '94704' }}
        run: |
          echo "ðŸš€ Starting Daily Ingredient Scraper"
          node scripts/daily-scraper.js

      - name: Database Maintenance (Post-Scrape Optimization)
        if: success()
        env:
          DB_URL: ${{ secrets.DATABASE_URL }}
        run: |
          echo "ðŸ“ˆ Updating database statistics for the new batch..."
          psql "$DB_URL" -c "ANALYZE public.ingredients_history;"
          psql "$DB_URL" -c "ANALYZE public.ingredients_recent;"

      - name: Report Success
        if: success()
        run: echo "âœ… Database wiped, items scraped, and history updated."