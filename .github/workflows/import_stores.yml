name: Import New Stores
on:
  workflow_dispatch:
    inputs:
      brands:
        description: "Comma- or space-separated store_enum values to target (optional). Leave empty to process all brands in parallel batches."
        required: false
      max_spiders:
        description: "Maximum number of spiders/brands to process per job (optional, default: 2)"
        required: false
        default: "2"

jobs:
  # Job for scheduled runs - processes all brands in parallel batches
  import-stores-scheduled:
    # Only run on scheduled events (not manual workflow_dispatch)
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    timeout-minutes: 45 # Reduced since each job processes fewer brands
    strategy:
      # Process brands in parallel to reduce load per job and total runtime
      # fail-fast: false ensures other brand groups continue even if one fails
      fail-fast: false
      matrix:
        # Split brands into groups of 2-3 for parallel processing
        # This significantly reduces load on All the Places API per job
        brand_group:
          - "aldi,kroger"
          - "safeway,meijer"
          - "target,traderjoes"
          - "99ranch,walmart"
          - "wholefoods"
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        # We need ijson for memory-efficient parsing
        run: |
          pip install requests supabase ijson

      - name: Update Target ZIP Codes
        # Refresh the list of ZIP codes to scrape based on user locations
        # Automatically adds neighboring ZIP codes (±5 from each user ZIP)
        # e.g., user in 94102 → also scrapes 94097-94101, 94103-94107
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: python scripts/update_target_zipcodes.py --neighbor-radius 5
        continue-on-error: true # Don't fail if this step fails

      - name: Import Stores (${{ matrix.brand_group }})
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          BRAND_FILTER: ${{ matrix.brand_group }}
          MAX_SPIDERS_PER_RUN: "2"
        run: python scripts/import_new_stores.py
        continue-on-error: false # Fail the job if import fails (other matrix jobs continue)

  # Job for manual runs - processes custom brands or all brands
  import-stores-manual:
    # Only run on manual workflow_dispatch events
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    timeout-minutes: 90 # Longer timeout for manual runs (may process all brands)
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install requests supabase ijson

      - name: Update Target ZIP Codes
        # Refresh the list of ZIP codes to scrape based on user locations
        # Automatically adds neighboring ZIP codes (±5 from each user ZIP)
        # e.g., user in 94102 → also scrapes 94097-94101, 94103-94107
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: python scripts/update_target_zipcodes.py --neighbor-radius 5
        continue-on-error: true # Don't fail if this step fails

      - name: Import Stores (Manual)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          BRAND_FILTER: ${{ github.event.inputs.brands }}
          MAX_SPIDERS_PER_RUN: ${{ github.event.inputs.max_spiders }}
        run: python scripts/import_new_stores.py
        continue-on-error: false
