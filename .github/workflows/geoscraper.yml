name: Real-time GeoScraper
on:
  workflow_dispatch:
    inputs:
      zip_code:
        description: 'ZIP(s) to scrape (comma separated)'
        required: true
      brand:
        description: 'Optional Brand filter'
        required: false

jobs:
  # Job 1: Expand ZIP codes by adding neighbors
  expand-zips:
    runs-on: ubuntu-latest
    outputs:
      expanded_zips: ${{ steps.expand.outputs.expanded_zips }}
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install supabase

      - name: Expand ZIP codes with neighbors
        id: expand
        run: |
          EXPANDED=$(python scripts/expand_zipcodes_with_neighbors.py --zips "${{ github.event.inputs.zip_code }}" --radius 5)
          echo "expanded_zips=$EXPANDED" >> $GITHUB_OUTPUT
          echo "Original ZIPs: ${{ github.event.inputs.zip_code }}"
          echo "Expanded ZIPs: $EXPANDED"

  # Job 2: Scrape stores in parallel across all brands
  scrape:
    needs: expand-zips
    if: needs.expand-zips.outputs.expanded_zips != ''  # Skip if no ZIPs need scraping
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false  # Continue other brands even if one fails
      matrix:
        brand: [aldi, kroger, safeway, meijer, target, traderjoes, 99ranch, walmart, wholefoods]
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: pip install supabase requests ijson urllib3

      - name: Run Geoscraper for ${{ matrix.brand }}
        run: |
          python scripts/geoscraper.py \
            --zip "${{ needs.expand-zips.outputs.expanded_zips }}" \
            --brand "${{ matrix.brand }}"

  # Job 3: Mark original ZIP codes as completed
  complete-events:
    needs: [expand-zips, scrape]
    if: always()  # Run even if scrape was skipped or some brands failed
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install supabase

      - name: Mark events as completed
        run: |
          python -c "
          import os
          from supabase import create_client
          url = os.environ.get('SUPABASE_URL')
          key = os.environ.get('SUPABASE_SERVICE_ROLE_KEY')
          supabase = create_client(url, key)
          zips = '${{ github.event.inputs.zip_code }}'.split(',')
          for z in zips:
              supabase.table('scraping_events').update({'status': 'completed'}).eq('zip_code', z.strip()).eq('status', 'processing').execute()
          print(f'âœ… Marked {len(zips)} events as completed')
          "
