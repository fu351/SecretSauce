name: Real-time GeoScraper
on:
  workflow_dispatch:
    inputs:
      zip_code:
        description: 'ZIP(s) to scrape (comma separated)'
        required: true
      brand:
        description: 'Optional Brand filter'
        required: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        # Added urllib3 and ensured all script requirements are met
        run: pip install supabase requests ijson urllib3

      - name: Run Geoscraper
        run: |
          python scripts/geoscraper.py --zip "${{ github.event.inputs.zip_code }}" \
          ${{ github.event.inputs.brand && format('--brand {0}', github.event.inputs.brand) || '' }}

      - name: Mark Events as Completed
        if: success()
        run: |
          # This SQL update marks all ZIPs in this batch as 'completed'
          # We use a simple python inline script to handle the Supabase call
          python -c "
          import os
          from supabase import create_client
          url = os.environ.get('SUPABASE_URL')
          key = os.environ.get('SUPABASE_SERVICE_ROLE_KEY')
          supabase = create_client(url, key)
          zips = '${{ github.event.inputs.zip_code }}'.split(',')
          for z in zips:
              supabase.table('scraping_events').update({'status': 'completed'}).eq('zip_code', z.strip()).eq('status', 'processing').execute()
          "